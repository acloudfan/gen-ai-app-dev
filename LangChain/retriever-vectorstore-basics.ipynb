{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0af15c7-e0a5-4770-a1a9-671d23cca360",
   "metadata": {},
   "source": [
    "# Retriever & Vectorstore basics\n",
    "\n",
    "https://python.langchain.com/docs/modules/data_connection/retrievers/\n",
    "\n",
    "#### Sample PDF\r\n",
    "Download it to local file system: https://constitutioncenter.org/media/files/constitution.pd\n",
    "\n",
    "#### Dependencies\n",
    "!pip install sentence-transformers chromad f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6c88e8-6060-46a9-8cef-8037e43d064c",
   "metadata": {},
   "source": [
    "## Part-1 : Retriever : ChromaDB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9dd0bef-7909-4b13-a032-f36c2d3ebd24",
   "metadata": {},
   "source": [
    "### 1. Load documents using a loader\n",
    "\n",
    "Use the PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78f63468-940b-4551-9b8e-bd671a065fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "# Change this \n",
    "pdf_source = 'C:/Users/raj/Downloads/us-constitution.pdf'\n",
    "\n",
    "pdf_loader = PyPDFLoader(pdf_source) \n",
    "\n",
    "documents = pdf_loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928db411-2a8b-4a1d-8d4f-b4ec53e3b5c6",
   "metadata": {},
   "source": [
    "### 2. Split the document into chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b91d50cc-3222-417f-bb3d-4e44b19a2d6e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks:  74\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "chunk_size = 1000\n",
    "\n",
    "chunk_overlap = 200\n",
    "\n",
    "pdf_text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = chunk_size,\n",
    "    chunk_overlap = chunk_overlap,\n",
    "    keep_separator = False,\n",
    "    strip_whitespace = True,\n",
    ")\n",
    "\n",
    "chunked_documents = pdf_text_splitter.split_documents(documents)\n",
    "\n",
    "print(\"Number of chunks: \", len(chunked_documents))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e26d8d2-8608-491e-bc05-562cc56e3c3a",
   "metadata": {},
   "source": [
    "### 3. ChromaDB Vectorstore : Generate the embeddings for the chunks & add \n",
    "\n",
    "In this sample we are using ChromaDB, but you may use any vector store.\n",
    "\n",
    "https://python.langchain.com/docs/integrations/vectorstores/chroma\n",
    "\n",
    "\n",
    "\n",
    "#### Parameters (check doc for additional parameters:\n",
    "https://api.python.langchain.com/en/stable/vectorstores/langchain_community.vectorstores.chroma.Chroma.html#langchain_community.vectorstores.chroma.Chroma\n",
    "\n",
    "* collection_name (required)\n",
    "* embedding_function (optional)\n",
    "* persist_directory (optional)\n",
    "* collection_metadata (optional)\n",
    "* client (optional)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c2b4496-f935-49dc-9041-6331fab20855",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b41ce24b1c043e9b017f020cde7e9f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.chroma.Chroma at 0x2917f6ef850>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings.sentence_transformer import (\n",
    "    SentenceTransformerEmbeddings,\n",
    ")\n",
    "\n",
    "# load it into Chroma using default embedding all-MiniLM-L6-v2\n",
    "collection_name = 'us-constitution'\n",
    "collection_metadata = {'embedding': 'all-MiniLM-L6-v2', 'chunk_size': chunk_size, 'chunk_overlap': chunk_overlap}\n",
    "\n",
    "embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "vector_store = Chroma(collection_name=collection_name, collection_metadata=collection_metadata, embedding_function=embedding_function)\n",
    "vector_store.add_documents(chunked_documents)\n",
    "\n",
    "vector_store"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406aeb00-777c-436d-b16d-587c8d29379a",
   "metadata": {},
   "source": [
    "### 4. Similarity - Search the vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8352fb98-e9f1-4b13-8bf0-9bbee802c546",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='dent, and the  Time and Place for commencing Proceedings \\nunder this Constitution  \\nThat after such Publication the Electors should be ap-  \\npointed, and the Senators and Representatives elected: That the Electors should meet on the Day fixed for the Election \\nof the President, and should transmit their Votes certified, \\nsigned, sealed and directed, as the Constitution requires, to the Secretary of the United States in Congress assembled, \\nthat the Senators and Representatives should convene at the Time  and Place  assigned;  that the Senators  should  appoint \\na President of the Senate, for the sole  Purpose of receiving, \\nopening and counting the Votes for President; and, that  \\nafter he shall be chosen, the Congress, together with the President, should, without Delay, proceed to execute this \\nConstitution  \\nBy the unanimous  Order of the Convention  \\nGo. Washington- Presidt:  \\nW. JACKSON  Secretary.  \\n \\n* Language  in brackets  has been changed  by amendment.', metadata={'page': 10, 'source': 'C:/Users/raj/Downloads/us-constitution.pdf'}),\n",
       " Document(page_content='cordingly, until the Disability be removed, or a President shall be elected.]*  \\nThe President shall, at stated  Times, receive for his Services, \\na Compensation, which shall neither be increased nor \\ndiminished during the Period for which he shall have been \\nelected, and he shall not receive within that Period any\\n \\nother Emolument from the United States, or any of them.  \\nBefore he enter on the Execution of his Office, he shall \\ntake the following Oath or Affirmation: - “I do solemnly \\nswear (or affirm) that I will faithfully execute the Office of \\nPresident of the United States, and will to the best of my Ability, preserve, protect and defend the Constitution of \\nthe United  States.”', metadata={'page': 5, 'source': 'C:/Users/raj/Downloads/us-constitution.pdf'})]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 2\n",
    "query = \"What did the president say about Ketanji Brown Jackson\"\n",
    "result_docs = vector_store.similarity_search(query, k = k)\n",
    "\n",
    "# Following is the same as above\n",
    "# result_docs = vector_store.search(search_type=\"similarity\", query=query, k=k)\n",
    "\n",
    "result_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23bfbbc-c64a-45d9-8dc1-494c284a2542",
   "metadata": {},
   "source": [
    "### 5. Similarity Search with Score\n",
    "\n",
    "https://api.python.langchain.com/en/latest/vectorstores/langchain_community.vectorstores.chroma.Chroma.html#langchain_community.vectorstores.chroma.Chroma.similarity_search_with_relevance_scores\n",
    "\n",
    "#### Relevance scores\n",
    "Relevance between [0,1]. Higher the better. 0 is dissimilar, 1 is most similar.\n",
    "\n",
    "##### Parameters\n",
    "* query (str) – input text\r\n",
    "* k (int) – Number of Documents to return. Defaults to 4.\n",
    "\n",
    "#### Distance scores\n",
    "Distance is a continuous number. Lower the better.\n",
    "\n",
    "##### Parameters\n",
    "* query (str) – Query text to search for.\r\n",
    "* k (int) – Number of results to return. Defaults to 4.\r\n",
    "* filter (Optional[Dict[str, str]]) – Filter by metadata. Defaults to None.\r\n",
    "* where_document (Optional[Dict[str, st\n",
    "\n",
    "#### Note\n",
    "Behavior depends on the specific vector database implementation.r]]) (Any) –"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1aca22b-bd18-4c44-b494-3ebacb546a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity_search_with_relevance_scores\n",
      "Metadata :  {'page': 10, 'source': 'C:/Users/raj/Downloads/us-constitution.pdf'}   Score :  0.01704647858189623\n",
      "Metadata :  {'page': 5, 'source': 'C:/Users/raj/Downloads/us-constitution.pdf'}   Score :  -0.02897627841175665\n",
      "similarity_search_with_score\n",
      "Metadata :  {'page': 10, 'source': 'C:/Users/raj/Downloads/us-constitution.pdf'}   Score :  1.390106201171875\n",
      "Metadata :  {'page': 5, 'source': 'C:/Users/raj/Downloads/us-constitution.pdf'}   Score :  1.4551922082901\n"
     ]
    }
   ],
   "source": [
    "k = 2\n",
    "\n",
    "query = \"What did the president say about Ketanji Brown Jackson\"\n",
    "\n",
    "result_docs_relevance = vector_store.similarity_search_with_relevance_scores(query, k = k)\n",
    "\n",
    "print(\"similarity_search_with_relevance_scores\")\n",
    "for result in result_docs_relevance:\n",
    "    print(\"Metadata : \", result[0].metadata, \"  Score : \",result[1])\n",
    "\n",
    "print(\"similarity_search_with_score\")\n",
    "result_docs_score = vector_store.similarity_search_with_score(query, k = k)\n",
    "\n",
    "for result in result_docs_score:\n",
    "    print(\"Metadata : \", result[0].metadata, \"  Score : \",result[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed744689-b92f-4e15-b019-8b5883bea65d",
   "metadata": {},
   "source": [
    "### 6. MMR\n",
    "Return docs selected using the maximal marginal relevance. Maximal marginal relevance optimizes for similarity to query AND diversity among selected documents.\n",
    "\n",
    "https://api.python.langchain.com/en/latest/vectorstores/langchain_community.vectorstores.chroma.Chroma.html#langchain_community.vectorstores.chroma.Chroma.max_marginal_relevance_search\n",
    "\n",
    "#### Parameters\n",
    "* query (str) – Text to look up documents similar to.\r\n",
    "* k (int) – Number of Documents to return. Defaults to 4.\r\n",
    "* fetch_k (int) – Number of Documents to fetch to pass to MMR algorithm.\r\n",
    "* lambda_mult (float) – Number between 0 and 1 that determines the degree of diversity among the results with 0 corresponding to maximum diversity and 1 to minimum diversity. Defaults to 0.5.\r\n",
    "* filter (Optional[Dict[str, str]]) – Filter by metadata. Defaults to None.\r\n",
    "* where_document (Optional[Dict[str, str]]) –"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aac9ea8b-3d06-408d-80e9-1f9c0b4555ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'page': 10, 'source': 'C:/Users/raj/Downloads/us-constitution.pdf'}\n",
      "{'page': 13, 'source': 'C:/Users/raj/Downloads/us-constitution.pdf'}\n"
     ]
    }
   ],
   "source": [
    "k = 2\n",
    "\n",
    "query = \"What did the president say about Ketanji Brown Jackson\"\n",
    "  \n",
    "# Control the diversity by setting betwee 0 & 1, 0 = Max diversity, Default = 0.5\n",
    "lambda_mult = 0.5\n",
    "\n",
    "result_docs_mmr = vector_store.max_marginal_relevance_search(query, k = k, lambda_mult = lambda_mult)\n",
    "\n",
    "for result in result_docs_mmr:\n",
    "    print(result.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80a7695-400a-4b6f-8bb6-c23f43a1668f",
   "metadata": {},
   "source": [
    "## Part-2 : Retriever : Information systems\n",
    "\n",
    "https://python.langchain.com/docs/integrations/retrievers\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc8fcc6-e774-4b2a-a62f-890f3ff1e819",
   "metadata": {},
   "source": [
    "### Arxiv\n",
    "https://python.langchain.com/docs/integrations/retrievers/arxiv\n",
    "\n",
    "https://api.python.langchain.com/en/latest/retrievers/langchain_community.retrievers.arxiv.ArxivRetriever.html#langchain_community.retrievers.arxiv.ArxivRetriever\n",
    "\n",
    "#### Dependency\n",
    "\n",
    "!pip install --upgrade --quiet  arxiv\n",
    "\n",
    "#### Creation Parameters\n",
    "* ARXIV_MAX_QUERY_LENGTH  default = 300\r\n",
    "* doc_content_chars_max  default = 4000\r\n",
    "* get_full_documents default = False /* Setting thito True s require*s pip install pymup*df */\r\n",
    "* load_all_available_meta default = False\r\n",
    "* load_max_docs    default = 100 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a7018fb-3c53-4a59-8fe8-60090c2673da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\raj\\anaconda3\\envs\\genai-course\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.retrievers import ArxivRetriever\n",
    "\n",
    "retriever = ArxivRetriever(load_max_docs=2)\n",
    "\n",
    "COT_Document_identifier = '2201.11903'\n",
    "\n",
    "results = retriever.get_relevant_documents(query = COT_Document_identifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a5fe7a9-0015-4319-8af8-d516e817844b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Entry ID': 'http://arxiv.org/abs/2201.11903v6',\n",
       " 'Published': datetime.date(2023, 1, 10),\n",
       " 'Title': 'Chain-of-Thought Prompting Elicits Reasoning in Large Language Models',\n",
       " 'Authors': 'Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed Chi, Quoc Le, Denny Zhou'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6a3f337-8f1d-4add-8059-6ea6488d7556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='We explore how generating a chain of thought -- a series of intermediate\\nreasoning steps -- significantly improves the ability of large language models\\nto perform complex reasoning. In particular, we show how such reasoning\\nabilities emerge naturally in sufficiently large language models via a simple\\nmethod called chain of thought prompting, where a few chain of thought\\ndemonstrations are provided as exemplars in prompting. Experiments on three\\nlarge language models show that chain of thought prompting improves performance\\non a range of arithmetic, commonsense, and symbolic reasoning tasks. The\\nempirical gains can be striking. For instance, prompting a 540B-parameter\\nlanguage model with just eight chain of thought exemplars achieves state of the\\nart accuracy on the GSM8K benchmark of math word problems, surpassing even\\nfinetuned GPT-3 with a verifier.' metadata={'Entry ID': 'http://arxiv.org/abs/2201.11903v6', 'Published': datetime.date(2023, 1, 10), 'Title': 'Chain-of-Thought Prompting Elicits Reasoning in Large Language Models', 'Authors': 'Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed Chi, Quoc Le, Denny Zhou'}\n"
     ]
    }
   ],
   "source": [
    "print(results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90d7aa03-2cc7-477f-a4d2-1a682aa15236",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = retriever.invoke(\"1605.08386\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "397c65e3-3b39-4304-ace5-8d0f43669b96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='Graphs on lattice points are studied whose edges come from a finite set of\\nallowed moves of arbitrary length. We show that the diameter of these graphs on\\nfibers of a fixed integer matrix can be bounded from above by a constant. We\\nthen study the mixing behaviour of heat-bath random walks on these graphs. We\\nalso state explicit conditions on the set of moves so that the heat-bath random\\nwalk, a generalization of the Glauber dynamics, is an expander in fixed\\ndimension.', metadata={'Entry ID': 'http://arxiv.org/abs/1605.08386v1', 'Published': datetime.date(2016, 5, 26), 'Title': 'Heat-bath random walks with Markov bases', 'Authors': 'Caprice Stanley, Tobias Windisch'})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a3c7a51-7677-4323-b008-ee1a8784df52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Graphs on lattice points are studied whose edges come from a finite set of\\nallowed moves of arbitrary length. We show that the diameter of these graphs on\\nfibers of a fixed integer matrix can be bounded from above by a constant. We\\nthen study the mixing behaviour of heat-bath random walks on these graphs. We\\nalso state explicit conditions on the set of moves so that the heat-bath random\\nwalk, a ge'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].page_content[:400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b76fa9-402c-4dbe-870c-62fc0b921d29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
