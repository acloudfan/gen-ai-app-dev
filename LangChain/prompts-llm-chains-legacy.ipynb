{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7071a6fa",
   "metadata": {},
   "source": [
    "# LLM and Chains\n",
    "\n",
    "LEGACY code do not use\n",
    "\n",
    "The code in this notebook shows the creation of a simple chain using the leagcy classes and with *LangChain Execution Language (LCEL)*\n",
    "\n",
    "https://python.langchain.com/v0.1/docs/expression_language/\n",
    "\n",
    "**Note**\n",
    "\n",
    "* You can try out different LLM combinations to test the chains\n",
    "* For selected LLM you will need to provide the key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c1fd60-1762-4b52-bb61-4ac20eae72cc",
   "metadata": {},
   "source": [
    "#### Google Colab\n",
    "If you are running the code in Google colab, install the packages by uncommenting/running the cell below\n",
    "\n",
    "* The API key file file will not be available\n",
    "* You will be prompted to provide the Cohere API Token\n",
    "\n",
    "Uncomment & run the code in the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "775ba17f-9c45-41b3-ae97-290520f3c0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "## The script is downloaded and run to setup the utils folder\n",
    "\n",
    "# !curl -H \"Accept: application/vnd.github.VERSION.raw\" https://raw.githubusercontent.com/acloudfan/gen-ai-app-dev/main/Setup/gcsetup.sh  > gcsetup.sh\n",
    "# !chmod u+x gcsetup.sh\n",
    "# !./gcsetup.sh -l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321edcab",
   "metadata": {},
   "source": [
    "## Setup the environment variable for API access\n",
    "\n",
    "#### NOTE\n",
    "You MUST change the path to your own environment file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d1ecad0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load the file that contains the API keys\n",
    "load_dotenv('C:\\\\Users\\\\raj\\\\.jupyter\\\\.env1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7aae5b94-b9d4-4ac5-a323-1c070527022c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting path so we can access the utils folder\n",
    "sys.path.append('../')\n",
    "sys.path.append('./')\n",
    "\n",
    "from utils.api_key_check_utility import api_key_check\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6070673f",
   "metadata": {},
   "source": [
    "## Create LLM\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652ab391-9c33-41e3-8848-930bf3034d4d",
   "metadata": {},
   "source": [
    "### option#1  Use Hugging Face model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9f6c3e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key NOT found in environment.\n",
      "Provide the  HUGGINGFACEHUB_API_TOKEN  : \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ········\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added key:  HUGGINGFACEHUB_API_TOKEN  to the environment.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\raj\\anaconda3\\envs\\gen-ai-app-dev-course\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:141: LangChainDeprecationWarning: The class `HuggingFaceEndpoint` was deprecated in LangChain 0.0.37 and will be removed in 0.3. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEndpoint`.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to C:\\Users\\raj\\.cache\\huggingface\\token\n",
      "Login successful\n",
      "\u001b[1mHuggingFaceEndpoint\u001b[0m\n",
      "Params: {'endpoint_url': None, 'task': None, 'model_kwargs': {}}\n",
      "\n",
      "The first Star Wars movie, now known as Star Wars: Episode IV - A New Hope, was released on May 25, 1977. It was initially called simply \"Star Wars\" and was a groundbreaking film that launched a new era of science fiction and blockbuster films. The film's success led to the creation of a larger \"Star Wars\" saga that includes several sequels and prequels.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.llms import HuggingFaceEndpoint\n",
    "\n",
    "prompt = \"In what year was the first first Star Wars movie released?\"\n",
    "\n",
    "def   create_hugging_face_llm(repo_id=\"mistralai/Mistral-7B-Instruct-v0.2\", args={}):\n",
    "\n",
    "        # Check if the the API key is available in environment - if not prompt for it \n",
    "        api_key = api_key_check(\"HUGGINGFACEHUB_API_TOKEN\")\n",
    "    \n",
    "        llm = HuggingFaceEndpoint(\n",
    "                        repo_id=repo_id, \n",
    "                        **args\n",
    "        )\n",
    "    \n",
    "        return llm\n",
    "\n",
    "## You may try out different HF models by passing the repo_id\n",
    "# model_id = 'google/flan-t5-xxl'\n",
    "# model_id = 'mistralai/Mistral-7B-Instruct-v0.2'\n",
    "# model_id = 'microsoft/Phi-3.5-mini-instruct'\n",
    "# model_id='google/gemma-2-2b-it'\n",
    "\n",
    "\n",
    "## Test it\n",
    "# llm_hf = create_hugging_face_llm()\n",
    "# print(llm_hf)\n",
    "# print(llm_hf.invoke(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc2fa82-e3ae-4d0b-9164-887f81900aaa",
   "metadata": {},
   "source": [
    "### option# 2 Use Google model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04fa2beb-cb17-4954-8e27-85dede8fc7f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key NOT found in environment.\n",
      "Provide the  GOOGLE_API_KEY  : \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ········\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added key:  GOOGLE_API_KEY  to the environment.\n",
      "\u001b[1mGoogleGenerativeAI\u001b[0m\n",
      "Params: {'model': 'gemini-1.5-flash', 'temperature': 0.7, 'top_p': None, 'top_k': None, 'max_output_tokens': None, 'candidate_count': 1}\n",
      "The first Star Wars movie, titled \"Star Wars: Episode IV – A New Hope\", was released in **1977**. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models\n",
    "\n",
    "from langchain_google_genai import GoogleGenerativeAI\n",
    "\n",
    "prompt = \"In what year was the first first Star Wars movie released?\"\n",
    "\n",
    "def create_google_llm(model='gemini-1.5-flash', args={}):\n",
    "\n",
    "    # Check if the the API key is available in environment - if not prompt for it \n",
    "    api_key = api_key_check(\"GOOGLE_API_KEY\")\n",
    "\n",
    "    # Get the key to be passed\n",
    "    GOOGLE_API_KEY=api_key.get_api_key() \n",
    "    \n",
    "    llm = GoogleGenerativeAI(model=model,google_api_key=GOOGLE_API_KEY, **args)\n",
    "\n",
    "    return llm\n",
    "\n",
    "  \n",
    "## Test it\n",
    "# llm_google = create_google_llm()\n",
    "# print(llm_google)\n",
    "# print(llm_google.invoke(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489d2692-244b-4563-976d-5d826a491035",
   "metadata": {},
   "source": [
    "### option#3 Use AI 21 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e24fa2e-34e2-4cb0-ac93-cb22c6e2dec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key NOT found in environment.\n",
      "Provide the  AI21_API_KEY  : \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ········\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added key:  AI21_API_KEY  to the environment.\n",
      "\u001b[1mAI21LLM\u001b[0m\n",
      "Params: {}\n",
      "\n",
      "The first Star Wars movie was released in 1977.\n"
     ]
    }
   ],
   "source": [
    "# https://python.langchain.com/v0.1/docs/integrations/llms/ai21/\n",
    "# https://api.python.langchain.com/en/latest/llms/langchain_community.llms.ai21.AI21.html\n",
    "from langchain_ai21 import AI21LLM\n",
    "\n",
    "prompt = \"In what year was the first first Star Wars movie released?\"\n",
    "\n",
    "def create_ai21_llm(model='j2-mid', args={}):\n",
    "\n",
    "    # Check if the the API key is available in environment - if not prompt for it \n",
    "    api_key = api_key_check(\"AI21_API_KEY\")\n",
    "    \n",
    "    llm = AI21LLM(model='j2-mid', **args)\n",
    "    \n",
    "    return llm\n",
    "\n",
    "## You may try out different models\n",
    "#model=\"j2-ultra\"\n",
    "#model=\"j2-mid\"\n",
    "#model=\"j2-light\"\n",
    "\n",
    "## Test it\n",
    "# llm_ai21 = create_ai21_llm() \n",
    "# print(llm_ai21)\n",
    "# print(llm_ai21.invoke(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888c57c5-703a-420a-8ed7-6ed4b365db31",
   "metadata": {},
   "source": [
    "### option#4 Create Open AI model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24cc8b52-99af-460c-b734-b1c7e453539b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key NOT found in environment.\n",
      "Provide the  OPENAI_API_KEY  : \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ········\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added key:  OPENAI_API_KEY  to the environment.\n",
      "\u001b[1mOpenAI\u001b[0m\n",
      "Params: {'model_name': 'gpt-3.5-turbo-instruct', 'temperature': 0.7, 'top_p': 1, 'frequency_penalty': 0, 'presence_penalty': 0, 'n': 1, 'logit_bias': {}, 'seed': None, 'logprobs': None, 'max_tokens': 256}\n",
      "\n",
      "\n",
      "The first Star Wars movie, \"Star Wars Episode IV: A New Hope\", was released in 1977.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import OpenAI\n",
    "\n",
    "prompt = \"In what year was the first first Star Wars movie released?\"\n",
    "\n",
    "def create_gpt_llm(model_name='gpt-3.5-turbo-instruct', args={}):\n",
    "\n",
    "    # Check if the the API key is available in environment - if not prompt for it \n",
    "    api_key = api_key_check(\"OPENAI_API_KEY\")\n",
    "    \n",
    "    llm = OpenAI(**args) \n",
    "    return llm\n",
    "\n",
    "## Test it\n",
    "# llm_openai = create_gpt_llm()\n",
    "# print(llm_openai)\n",
    "# print(llm_openai.invoke(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a854c961-5219-4164-82db-1abfe19ced8f",
   "metadata": {},
   "source": [
    "### option#5 Create Cohere model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12f354c6-22ed-4148-b65f-f5a40b57fb4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key NOT found in environment.\n",
      "Provide the  COHERE_API_KEY  : \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ········\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added key:  COHERE_API_KEY  to the environment.\n",
      "client=<cohere.client.Client object at 0x000001336BE89A00> async_client=<cohere.client.AsyncClient object at 0x000001336D523C50> cohere_api_key=SecretStr('**********')\n",
      "The first Star Wars movie, now known as \"Star Wars: Episode IV - A New Hope,\" was released in 1977. It introduced the world to the iconic characters of Luke Skywalker, Princess Leia, Han Solo, and Darth Vader, and it became a cultural phenomenon, sparking a passion for science fiction and space adventure that continues to this day.\n"
     ]
    }
   ],
   "source": [
    "from langchain_cohere import ChatCohere\n",
    "\n",
    "def create_cohere_llm(model=\"command-light\", args={}):\n",
    "    \n",
    "    # Check if the Open AI key is available\n",
    "    cohere_api_key = api_key_check(\"COHERE_API_KEY\")\n",
    "\n",
    "    llm = ChatCohere(**args) \n",
    "    return llm\n",
    "\n",
    "## You may try out different models\n",
    "#model=\"command-light\"\n",
    "#model=\"command-r\"\n",
    "    \n",
    "## Test it\n",
    "# llm_cohere = create_cohere_llm()\n",
    "# print(llm_cohere)\n",
    "# print(llm_cohere.invoke(prompt).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eaa99e9",
   "metadata": {},
   "source": [
    "## 2. LLMChain\n",
    "\n",
    "Chains refer to sequences of calls - whether to an LLM, a tool, or a data preprocessing step\n",
    "\n",
    "https://python.langchain.com/docs/modules/chains\n",
    "\n",
    "https://api.python.langchain.com/en/stable/chains/langchain.chains.llm.LLMChain.html#langchain.chains.llm.LLMChain\n",
    "\n",
    "https://api.python.langchain.com/en/latest/llms/langchain_community.llms.huggingface_endpoint.HuggingFaceEndpoint.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eaf75382",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "superbowl_template = \"who won super bowl in year {year}?\"\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    template = superbowl_template,\n",
    "    input_variables = [\"year\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db74fa3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import LLMChain\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# You may switch LLM\n",
    "llm_1 = create_google_llm()\n",
    "\n",
    "# Create a simple chain - This method is getting deprecated !!\n",
    "# simple_chain = LLMChain(\n",
    "#             prompt = prompt_template, \n",
    "#             llm = llm_1,\n",
    "#             output_key = \"superbowl_winner\"\n",
    "#         )\n",
    "\n",
    "# Runnable sequence\n",
    "simple_chain = prompt_template | llm_1 | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c333c04d-b36d-48b2-b01d-7bfd3810ed5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The **Oakland Raiders** won Super Bowl XI in 1977, defeating the Minnesota Vikings 32-14. \\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Both the lines will yield the same result\n",
    "\n",
    "response = simple_chain.invoke(1977)    \n",
    "\n",
    "# response = chain.invoke({\"year\": 1977})\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73c7e8e",
   "metadata": {},
   "source": [
    "## 3. Simple Sequential Chain\n",
    "\n",
    "Use **Chain-1** to answer a question. Then send the question/answer pair to **Chain-2** to verify if the answer is correct or not.\n",
    "\n",
    "https://api.python.langchain.com/en/stable/chains/langchain.chains.sequential.SimpleSequentialChain.html#langchain.chains.sequential.SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed892043",
   "metadata": {},
   "source": [
    "### Create a LLMChain - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5de530d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to C:\\Users\\raj\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' as a vector quantity, which has both magnitude and direction. The momentum of an object is given by the product of its mass and velocity: p = mv. In classical mechanics, momentum is a conserved quantity, meaning that the total momentum of a closed system remains constant unless acted upon by an external force. In quantum mechanics, momentum is an observable property, represented by an operator in the Schrödinger equation, and the uncertainty principle relates the uncertainty in position to the uncertainty in momentum. The SI unit for momentum is kilogram meter per second (kg⋅m/s).\\n\\nThe concept of momentum is important in physics because it allows for a more complete description of the motion of objects. By considering both the mass and velocity of an object, we can better understand the effects of forces on the object and predict how it will move in response to those forces. Additionally, the conservation of momentum is a fundamental principle of physics that underlies many important laws and applications, such as the conservation of energy and the behavior of systems in collisions.\\n\\nOne useful application of momentum is in the analysis of particle interactions in high-energy physics experiments. By measuring the momentum and other properties of particles before and after an interaction, physicists can determine the types and quantities of particles involved and test theories of particle physics. Momentum is also an important concept in the study of waves, where it is related to the wave vector and the particle-like behavior of waves in certain circumstances.\\n\\nIn summary, momentum is a vector quantity that describes the mass and velocity of an object, and is a conserved quantity in classical mechanics. It is an important concept in physics that allows for a more complete description of the motion of objects and underlies many important laws and applications.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Template for chain 1 simply say define a term\n",
    "\n",
    "llm_1 = create_hugging_face_llm()\n",
    "\n",
    "prompt_template_1 = PromptTemplate.from_template(\n",
    "    template=\"define {term}\", \n",
    "    inputs=['term']\n",
    ")\n",
    "\n",
    "# Create the LLM chain object - This method of chain creation is now deprecated\n",
    "# llm_chain_1 = LLMChain(\n",
    "#     llm = llm_1,\n",
    "#     prompt = prompt_template_1,\n",
    "#     output_key = \"definition\"\n",
    "# )\n",
    "\n",
    "llm_chain_1 = prompt_template_1 | llm_1 \n",
    "\n",
    "## example\n",
    "llm_chain_1.invoke(\"momentum\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a38a4df",
   "metadata": {},
   "source": [
    "### Create the LLMChain-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ebc1bd3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['definition'], template='rate the accuracy of the definition on a scale of (0 to 5).\\n                Definition of :  {definition}')\n",
       "| OpenAI(client=<openai.resources.completions.Completions object at 0x0000015E1C5F37A0>, async_client=<openai.resources.completions.AsyncCompletions object at 0x0000015E1E150DA0>, openai_api_key=SecretStr('**********'), openai_proxy='')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Template for OpenAI\n",
    "prompt_template_2 = PromptTemplate.from_template(\n",
    "    template=\"\"\"rate the accuracy of the definition on a scale of (0 to 5).\n",
    "                Definition of :  {definition}\"\"\", \n",
    "    inputs=['definition']\n",
    ")\n",
    "\n",
    "## The following template if used with SimpleSequentialChain will FAIL\n",
    "## Added for demonstration purposes only - to try uncomment the code below\n",
    "# prompt_template_openai =PromptTemplate.from_template(template=\"\"\"\n",
    "# rate the accuracy of the definition on a scale of (0 to 5).\n",
    "# Definition of {term}:  {definition}\"\"\", inputs=['definition','term'])\n",
    "\n",
    "llm_2 = create_gpt_llm()\n",
    "\n",
    "# This method of creating chains is now deprecated\n",
    "# llm_chain_2 = LLMChain(\n",
    "#     llm = llm_2,\n",
    "#     prompt = prompt_template_2,\n",
    "#     output_key = \"score\"\n",
    "# )\n",
    "\n",
    "llm_chain_2 = prompt_template_2 | llm_2\n",
    "\n",
    "llm_chain_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "930371ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://api.python.langchain.com/en/latest/chains/langchain.chains.sequential.SequentialChain.html\n",
    "from langchain.chains import SimpleSequentialChain\n",
    "from operator import itemgetter\n",
    "\n",
    "# This method of creating a sequential chain is now deprecated\n",
    "# simple_sequential_chain = SimpleSequentialChain(\n",
    "#     chains=[llm_chain_1, llm_chain_2],\n",
    "#     verbose = True,\n",
    "# )\n",
    "\n",
    "simple_sequential_chain = ({\n",
    "        \"definition\" : llm_chain_1\n",
    "    } | llm_chain_2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "37eea656",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nI would rate this definition a 4 out of 5. It is clear and provides step-by-step instructions on how to calculate the moment of inertia. However, it could benefit from including a visual example or diagram to further clarify the concept.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input = String value if there is ONLY one input variable\n",
    "# Input = Dictionary if there are multiple input variables\n",
    "\n",
    "response = simple_sequential_chain.invoke(\"moment of interia\")\n",
    "\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
