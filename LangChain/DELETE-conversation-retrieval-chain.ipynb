{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67ee996c-3837-4472-9de5-54198716d55a",
   "metadata": {},
   "source": [
    "# Stuff Documents Chain\n",
    "Takes a set of documents and passes it as a context to the LLM. The documents may be retrived from a retrival system.\n",
    "\n",
    "https://python.langchain.com/docs/get_started/quickstart/\n",
    "\n",
    "https://api.python.langchain.com/en/latest/chains/langchain.chains.combine_documents.stuff.create_stuff_documents_chain.html\n",
    "\n",
    "## Document chunking and Vector DB setup\n",
    "generative-ai-for-architects/LangChain/retriever-vectorstore-basics.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b089b5d-488e-48eb-8c5a-411dee2f748b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pymupdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d154f5-e7e3-4e25-94f9-61ad4ab0f92e",
   "metadata": {},
   "source": [
    "## Setup LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4691b665-74df-4357-9996-076809d50304",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import sys\n",
    "import json\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Load the file that contains the API keys - OPENAI_API_KEY\n",
    "load_dotenv('C:\\\\Users\\\\raj\\\\.jupyter\\\\.env')\n",
    "\n",
    "# setting path\n",
    "sys.path.append('../')\n",
    "\n",
    "from utils.create_llm import create_gpt_llm, create_anthropic_llm, create_ai21_llm, create_cohere_llm, create_hugging_face_llm\n",
    "\n",
    "# Try with GPT\n",
    "# model=\"gpt-4\"\n",
    "# llm = create_gpt_llm({\"model\": model})\n",
    "\n",
    "llm = create_hugging_face_llm(repo_id='mistralai/Mistral-7B-Instruct-v0.3', args={\"max_new_tokens\":1024})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35a1a2d-1bed-4275-bb7b-60613390ab47",
   "metadata": {},
   "source": [
    "## Setup Retriever function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d58f36-71c9-46ce-a171-b098a4995fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.retrievers import ArxivRetriever\n",
    "\n",
    "def get_arxiv_docs(query):\n",
    "    # Retrieve full documents, with as much info as possible\n",
    "    retriever = ArxivRetriever(load_max_docs=1, get_full_documents=True, doc_content_chars_max=30000)\n",
    "    return retriever.get_relevant_documents(query = query)\n",
    "\n",
    "# # Chain of Thought paper\n",
    "# COT_Document_identifier = 'chain of thought' # 2201.11903'\n",
    "\n",
    "# results = retriever.get_relevant_documents(query = COT_Document_identifier)\n",
    "\n",
    "# print(len(results))\n",
    "# results[0].metadata\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43198117-a47d-4bda-bcae-778a60e335cb",
   "metadata": {},
   "source": [
    "## RAG\n",
    "Idea is to setup LLM for Q&A:\n",
    "\n",
    "1. Retrieve Arxiv documents on topics of interest\n",
    "2. Create a RAG LLM chain with the relevant docs\n",
    "3. Ask questions on topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583a09fc-574d-46e2-a115-b007c3dd9ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"You are a smart agent who uses only the provided provided context to carry out the given task. \\n\\n Task: {task} \\n\\n Context: \\n {context}\",\n",
    "    input_variables=[\"task\", \"context\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ae1101-7bd5-4e10-a16a-f481e295a9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = create_stuff_documents_chain(llm, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb126e1-2862-4409-95fd-77c8d31a3067",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = \"chain of thought\"\n",
    "task=\"explain COT to a 15 year old\"\n",
    "\n",
    "docs = get_arxiv_docs(topic)\n",
    "# result = chain.invoke({\"task\": task, \"context\": docs})\n",
    "\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d0daad-7baf-4398-85b2-8fb7a25744d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "task=\"what is chain of thought?\"\n",
    "# task=\"create a bullet point list of important points\"\n",
    "result = llm.invoke(prompt.format(task=task, context=docs[0].page_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bf5e27-c68d-484c-82b8-dc8e5f494a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10edcad5-9099-4eca-aeda-d2fc7939aae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8dc2e4-0f3d-4a90-bbbe-ba3ed7648758",
   "metadata": {},
   "source": [
    "## 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f7f284-9f1d-4ce7-ab0c-606bb0e068f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.retrievers import WikipediaRetriever\n",
    "retriever = WikipediaRetriever()\n",
    "\n",
    "topic = \"LLM Chain of Thought\"\n",
    "docs = retriever.invoke(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd93e0fa-40d6-4665-a726-97f581d01f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031945c3-3b58-408f-bec7-25923669c76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "llm = create_hugging_face_llm(repo_id='mistralai/Mistral-7B-Instruct-v0.3') #, args={\"max_new_tokens\":1024})\n",
    "chain = create_stuff_documents_chain(llm, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235d9003-9ae1-49af-ab60-08f386b7e244",
   "metadata": {},
   "outputs": [],
   "source": [
    "task=\"create a bullet point list that exaplains the chain of thought technique\"\n",
    "result = chain.invoke({\"task\": task, \"context\": docs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972df158-552f-4e00-b05f-d318b9852b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03613ead-9b99-477f-ae7a-0416c4a23553",
   "metadata": {},
   "outputs": [],
   "source": [
    "task=\"describe COT technique in simple terms\"\n",
    "result = chain.invoke({\"task\": task, \"context\": docs})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3261c132-6c5b-4d24-90ca-f9afa6b01ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "task=\"give me an example of how to apply chain of thought technique\"\n",
    "result = chain.invoke({\"task\": task, \"context\": docs})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a967581-fbc7-4f8b-bfdd-da9e99138f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "task=\"create a summary for the chain of thought technique\"\n",
    "result = chain.invoke({\"task\": task, \"context\": docs})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cabcaf-86d2-430f-8a87-7df8e39fb80f",
   "metadata": {},
   "source": [
    "# 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a80110-ad60-4af6-a3d0-527620b4389e",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = ''\n",
    "for doc in docs:\n",
    "    \n",
    "    context = \"\\n\" + context + doc.page_content\n",
    "\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8434c8-ca50-47cc-977e-2ebb5edc1a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "task=\"what is chain of thought technique\"\n",
    "result = llm.invoke(prompt.format(task=task, context=context))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dba9a13-2813-4fad-aa72-97e231c3b8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "task=\"give me an example of chain of thought technique\"\n",
    "result = llm.invoke(prompt.format(task=task, context=context))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816c49f6-812f-45db-8a03-3d8b0792be52",
   "metadata": {},
   "outputs": [],
   "source": [
    "task=\"create a list of 5 points that explains the chain of thought technique\"\n",
    "result = llm.invoke(prompt.format(task=task, context=context))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23dab851-7133-4756-8928-0b02b0033c2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
