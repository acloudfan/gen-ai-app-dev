{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7071a6fa",
   "metadata": {},
   "source": [
    "# Try out the real LLMs\n",
    "\n",
    "The code in this notebook shows the creation of LLMs\n",
    "\n",
    "\n",
    "**Note**\n",
    "\n",
    "* You can try the Models for which you have setup the keys\n",
    "* You may experiment with additonal models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c1fd60-1762-4b52-bb61-4ac20eae72cc",
   "metadata": {},
   "source": [
    "#### Google Colab\n",
    "If you are running the code in Google colab, install the packages by uncommenting/running the cell below\n",
    "\n",
    "* The API key file file will not be available\n",
    "* You will be prompted to provide the Cohere API Token\n",
    "\n",
    "Uncomment & run the code in the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775ba17f-9c45-41b3-ae97-290520f3c0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "## The script is downloaded and run to setup the utils folder\n",
    "\n",
    "# !curl -H \"Accept: application/vnd.github.VERSION.raw\" https://raw.githubusercontent.com/acloudfan/gen-ai-app-dev/main/Setup/gcsetup.sh  > gcsetup.sh\n",
    "# !chmod u+x gcsetup.sh\n",
    "# !./gcsetup.sh -l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321edcab",
   "metadata": {},
   "source": [
    "## Setup the environment variable for API access\n",
    "\n",
    "#### NOTE\n",
    "You MUST change the path to your own environment file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d1ecad0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load the file that contains the API keys\n",
    "load_dotenv('C:\\\\Users\\\\raj\\\\.jupyter\\\\.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7aae5b94-b9d4-4ac5-a323-1c070527022c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting path so we can access the utils folder\n",
    "sys.path.append('../')\n",
    "sys.path.append('./')\n",
    "\n",
    "from utils.api_key_check_utility import api_key_check\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b42ede1-1897-4692-9d70-04ba385696b4",
   "metadata": {},
   "source": [
    "## Part-1\n",
    "## Try out real LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652ab391-9c33-41e3-8848-930bf3034d4d",
   "metadata": {},
   "source": [
    "### 1. Hugging Face model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9f6c3e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key:  HUGGINGFACEHUB_API_TOKEN  already set in environment.\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to C:\\Users\\raj\\.cache\\huggingface\\token\n",
      "Login successful\n",
      "\n",
      "\n",
      "Answer: 1977\n",
      "\n",
      "Star Wars, the space opera epic film created by George Lucas, was first released in the United States on May 25, 1977. The movie's impact was immediate and transformative, ushering in a new era of science fiction and blockbuster cinema. The original Star Wars trilogy, which includes 'Star Wars' (Episodes IV, V, and VI), 'The Empire Strikes Back' (Episode V), and 'Return of the Jedi' (Episode VI), has since become one of the most iconic and influential franchises in the history of cinema.\n",
      "\n",
      "\n",
      "Answer: 1990\n",
      "\n",
      "The first \"Home Alone\" movie, featuring Macaulay Culkin as Kevin McCallister, was released in the United States on November 16, 1990. The film tells the story of an eight-year-old boy who is inadvertently left behind when his family goes on a vacation. Kevin must fend for himself against burglars while preparing for the holiday season. The movie was a huge commercial success and spawned several sequels.\n",
      "\n",
      "\n",
      "Answer:\n",
      "\n",
      "The first Harry Potter movie, titled \"Harry Potter and the Philosopher's Stone\" or \"Harry Potter and the Sorcerer's Stone\" in some countries, was released on November 14, 2001. This date refers to its premiere in the United Kingdom; in the United States and other countries, it was released on November 16, 2001.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.llms import HuggingFaceEndpoint\n",
    "\n",
    "prompt = \"In what year was the first Star Wars movie released?\"\n",
    "\n",
    "def   create_hugging_face_llm(repo_id=\"mistralai/Mistral-7B-Instruct-v0.2\", args={}):\n",
    "\n",
    "        # Check if the the API key is available in environment - if not prompt for it \n",
    "        api_key = api_key_check(\"HUGGINGFACEHUB_API_TOKEN\")\n",
    "    \n",
    "        llm = HuggingFaceEndpoint(\n",
    "                        repo_id=repo_id, \n",
    "                        **args\n",
    "        )\n",
    "    \n",
    "        return llm\n",
    "\n",
    "## You may try out different HF models by passing the repo_id\n",
    "# model_id = 'google/flan-t5-xxl'\n",
    "# model_id = 'mistralai/Mistral-7B-Instruct-v0.2'\n",
    "# model_id = 'microsoft/Phi-3.5-mini-instruct'\n",
    "model_id='google/gemma-2-2b-it'\n",
    "\n",
    "\n",
    "## Create LLM\n",
    "llm_hf = create_hugging_face_llm()\n",
    "# print(llm_hf)\n",
    "\n",
    "## ---------------Call invoke--------------- ####\n",
    "## Call invoke\n",
    "# print(llm_hf.invoke(prompt))\n",
    "\n",
    "## ---------------Call stream--------------- ####\n",
    "## Notice returned tokens are words not characters (as seen with Fakes)\n",
    "\n",
    "# for chunk in llm_hf.stream(prompt):\n",
    "#     print(chunk)\n",
    "\n",
    "## --------------Call batch----------------- ####\n",
    "## Returns a list of responses\n",
    "\n",
    "## Input is a list\n",
    "batch_inputs = [\n",
    "    \"In what year was the first 'Star Wars' movie released?\",\n",
    "    \"In what year was the first 'home alone' movie released?\",\n",
    "    \"In what year was the first 'harry potter' movie released?\"\n",
    "]\n",
    "\n",
    "## Response is a list\n",
    "response = llm_hf.batch(batch_inputs)\n",
    "for answer in response:\n",
    "    print(answer)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc2fa82-e3ae-4d0b-9164-887f81900aaa",
   "metadata": {},
   "source": [
    "### 2. Google Gemini model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fa2beb-cb17-4954-8e27-85dede8fc7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models\n",
    "\n",
    "from langchain_google_genai import GoogleGenerativeAI\n",
    "\n",
    "prompt = \"In what year was the first first Star Wars movie released?\"\n",
    "\n",
    "def create_google_llm(model='gemini-1.5-flash', args={}):\n",
    "\n",
    "    # Check if the the API key is available in environment - if not prompt for it \n",
    "    api_key = api_key_check(\"GOOGLE_API_KEY\")\n",
    "\n",
    "    # Get the key to be passed\n",
    "    GOOGLE_API_KEY=api_key.get_api_key() \n",
    "    \n",
    "    llm = GoogleGenerativeAI(model=model,google_api_key=GOOGLE_API_KEY, **args)\n",
    "\n",
    "    return llm\n",
    "\n",
    "  \n",
    "## Test it\n",
    "# llm_google = create_google_llm()\n",
    "# print(llm_google)\n",
    "# print(llm_google.invoke(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489d2692-244b-4563-976d-5d826a491035",
   "metadata": {},
   "source": [
    "### 3. AI 21 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e24fa2e-34e2-4cb0-ac93-cb22c6e2dec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://python.langchain.com/v0.1/docs/integrations/llms/ai21/\n",
    "# https://api.python.langchain.com/en/latest/llms/langchain_community.llms.ai21.AI21.html\n",
    "from langchain_ai21 import AI21LLM\n",
    "\n",
    "prompt = \"In what year was the first first Star Wars movie released?\"\n",
    "\n",
    "def create_ai21_llm(model='j2-mid', args={}):\n",
    "\n",
    "    # Check if the the API key is available in environment - if not prompt for it \n",
    "    api_key = api_key_check(\"AI21_API_KEY\")\n",
    "    \n",
    "    llm = AI21LLM(model='j2-mid', **args)\n",
    "    \n",
    "    return llm\n",
    "\n",
    "## You may try out different models\n",
    "#model=\"j2-ultra\"\n",
    "#model=\"j2-mid\"\n",
    "#model=\"j2-light\"\n",
    "\n",
    "## Test it\n",
    "# llm_ai21 = create_ai21_llm() \n",
    "# print(llm_ai21)\n",
    "# print(llm_ai21.invoke(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888c57c5-703a-420a-8ed7-6ed4b365db31",
   "metadata": {},
   "source": [
    "### 4. Create Open AI model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cc8b52-99af-460c-b734-b1c7e453539b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI\n",
    "\n",
    "prompt = \"In what year was the first first Star Wars movie released?\"\n",
    "\n",
    "def create_gpt_llm(model_name='gpt-3.5-turbo-instruct', args={}):\n",
    "\n",
    "    # Check if the the API key is available in environment - if not prompt for it \n",
    "    api_key = api_key_check(\"OPENAI_API_KEY\")\n",
    "    \n",
    "    llm = OpenAI(**args) \n",
    "    return llm\n",
    "\n",
    "## Test it\n",
    "# llm_openai = create_gpt_llm()\n",
    "# print(llm_openai)\n",
    "# print(llm_openai.invoke(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a854c961-5219-4164-82db-1abfe19ced8f",
   "metadata": {},
   "source": [
    "### 5. Create Cohere model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f354c6-22ed-4148-b65f-f5a40b57fb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_cohere import ChatCohere\n",
    "\n",
    "def create_cohere_llm(model=\"command-light\", args={}):\n",
    "    \n",
    "    # Check if the Open AI key is available\n",
    "    cohere_api_key = api_key_check(\"COHERE_API_KEY\")\n",
    "\n",
    "    llm = ChatCohere(**args) \n",
    "    return llm\n",
    "\n",
    "## You may try out different models\n",
    "#model=\"command-light\"\n",
    "#model=\"command-r\"\n",
    "    \n",
    "## Test it\n",
    "# llm_cohere = create_cohere_llm()\n",
    "# print(llm_cohere)\n",
    "# print(llm_cohere.invoke(prompt).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625af01a-8a72-49fd-bb52-942b93d053bd",
   "metadata": {},
   "source": [
    "## Part-2 \n",
    "## Use the LLM-utility to create LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b792a6ed-12e8-4e55-840d-19ba7a84ac34",
   "metadata": {},
   "source": [
    "As a conveneince, you can use a utility for creating LLMs. The utility is available as a Python module in the course notebooks. To use it, you would import the approrpriate create_xxx function and use it for creating an instance of the utility.\n",
    "\n",
    "* Utility expects the appropriate API Key to be available in the environment\n",
    "* As a best practice use the utility **api_key_check** for checking the availablity of key and for prompting for key\n",
    "* Google Colab : The gcsetup script downloads & adds the utility modules to local filesystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b982dfa-9435-466b-8e11-80165ee44779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example : Google LLM creation. For other LLMs checkout notebook: gen-ai-app-dev/Gen-AI-Fundamentals/setup-test-api-keys.ipynb\n",
    "from utils.create_llm import create_google_llm\n",
    "\n",
    "# Check if the key is available\n",
    "api_key = api_key_check(\"GOOGLE_API_KEY\")\n",
    "\n",
    "# Try out the Gemini Flash model\n",
    "# model=\"gemini-1.5-flash\" - created by default\n",
    "llm = create_google_llm()\n",
    "\n",
    "# Uncomment to create the pro model\n",
    "# llm=create_google_llm(model=\"gemini-1.5-pro\")\n",
    "\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec09dcdd-4c7f-496d-ae5d-e06567f1d091",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm.invoke(\"who was the main characters in the movie sound of music\")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27063617-f2c6-496c-a4b6-cc40c0e4c4b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
